# Machine Learning and Explainable AI for Well-Being Prediction

**Datagotchi Health** is a research platform combining **machine learning** and **behavioral experimentation** to investigate how lifestyle and socio-demographic factors relate to **mental well-being**, and how different explanation formats affect usersâ€™ understanding, trust, and behavior.  
The repository includes all code supporting two empirical studies:

1. **Study 1 â€“ Predictive Modeling:** Development and validation of machine learning models predicting well-being from lifestyle data.  
2. **Study 2 â€“ Explainability Experiment:** Online evaluation of five explanation modalities for model outputs through an interactive web application.

---

## âš™ï¸ Reproducibility and Data Access

All analyses were conducted in **Python 3.9** and **R 4.3**, with dependencies managed via **Poetry** for environment reproducibility.  

Data used for Study 1 were collected through the **LÃ©ger Panel**, while Study 2 used data from **Prolific**.  
Because the datasets contain human-subject information, raw data are **not publicly available**.  
Processed or synthetic examples may be shared upon request in compliance with ethics protocols.

---

## ğŸ§­ Getting Started

To reproduce or extend the analyses and experiments, please follow these steps:

1. **Install required software**

   Ensure you have the following installed on your system:
   - **Python 3.9**
   - **R 4.3**
   - **Make**
   - **Poetry** (for Python dependency management)

2. **Create a `.env` file**

   In the project root directory, create a file named `.env` containing the following paths and configuration variables:

   ```bash
   # Paths for Study 1 (Machine Learning)
   DATA_PATH='path/to/ml/data'

   # Paths for Study 2 (Web Application Experiment)
   DATA_WEBAPP_PATH='/path/to/webapp/data'
   SECRET_KEY='your_secret_key_here'                   # Protects the web app database
   PROLIFIC_STUDY_ID='your_prolific_study_id_here'     # Used when running the experiment on Prolific
   PROLIFIC_COMPLETION_CODE='your_completion_code_here' # Used for study completion validation

---

## ğŸ§© Repository Structure
```
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ auth
â”‚Â Â  â”œâ”€â”€ main
â”‚Â Â  â”œâ”€â”€ ml
â”‚Â Â  â”œâ”€â”€ models.py
â”‚Â Â  â”œâ”€â”€ recommend
â”‚Â Â  â”œâ”€â”€ static
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ css
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data
â”‚Â Â  â”‚Â Â  â””â”€â”€ img
â”‚Â Â  â””â”€â”€ templates
â”‚Â Â      â”œâ”€â”€ auth
â”‚Â Â      â””â”€â”€ main
â”œâ”€â”€ config.py
â”œâ”€â”€ deploy
â”‚Â Â  â”œâ”€â”€ microapp.conf
â”‚Â Â  â””â”€â”€ microapp_nginx
â”œâ”€â”€ microapp.py
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ scripts
â””â”€â”€ study_2.R
```
- **Makefile** â€” Automates the workflow for Study 1 and Study 2, including feature generation, model training, and data tracking.  
- **app/** â€” Contains all web application files for Study 2, as well as the machine learning models developed in Study 1 (see `app/ml`).  
- **config.py** â€” Configuration file for the Flask web app (database, API keys, and environment settings).  
- **deploy/** â€” Contains example configuration files for server deployment using **Nginx** and **Supervisor**.  
- **microapp.py** â€” Entry point to launch the Flask web application locally or on a remote server.  
- **poetry.lock** and **pyproject.toml** â€” Define and lock Python dependencies to ensure reproducibility via **Poetry**.  
- **scripts/** â€” Helper scripts to facilitate launching the web app, populating the database, and handling experiment logistics.  
- **study_2.R** â€” R script conducting the statistical analysis of behavioral and survey data collected during Study 2.  



## ğŸš€ Study 1 â€” Running the Machine Learning Pipeline

The **Makefile** automates the entire workflow, from feature generation to model evaluation. All model configurations and parameter grids are stored in the directory `app/ml/configs`, allowing full reproducibility and easy modification of model settings. 
Below is an overview of key commands:

| Command | Description |
|----------|-------------|
| `make create-features` | Generates model input features from the raw questionnaire data. |
| `make select-features` | Selects the most informative predictors using XGBoost feature importance. |
| `make run-crossval` | Runs nested cross-validation for model comparison and hyperparameter tuning. |
| `make regular-track` | Monitors new experimental data on the remote server. |
| `make regular-download` | Downloads updated results from the remote server for local analysis. |

To reproduce Study 1 model training:

```bash
make create-features
make select-features
make run-crossval
```

## ğŸ§ª Study 2 â€” Online Explainability Experiment

Study 2 builds upon the predictive model developed in Study 1 and investigates how different **explanation formats** influence usersâ€™ interpretation of their predicted well-being scores.  
An interactive **Flask web application** serves as the experimental platform, where participants are randomly assigned to one of five explanation conditionsâ€”**contextual**, **quantitative**, **textual**, **visual**, or **interactive**â€”or to a control condition without explanation.

Each condition presents a distinct communication strategy for model reasoning, implemented dynamically using HTML templates and Flask rendering logic.  
Participant interactions, response times, and navigation behaviors are automatically logged for later analysis.

To launch the web interface locally:

```bash
python app/microapp.py
```

### ğŸŒ Running the Application on a Remote Server

The web application can also be deployed on a remote server for conducting online experiments.  
Once the experiment is running, data can be continuously monitored and synchronized between the server and your local machine.

#### Tracking and Synchronizing Experimental Data

- **On the remote server:**  
  Start automatic tracking of new incoming participant data  
  ```bash
  make regular-track
  ```

- **On the remote server:**  
  Download the latest experimental data from the remote server
  ```bash
  make regular-download vm=trainmachine DATA_EXPERIMENT_PATH='/root/deploy/data'
  ```
  
### Behavioral and Statistical Analysis

The file `analysis/study_2.R` reproduces the statistical analysis of Study 2, including manipulation checks, between-condition comparisons, and hypothesis testing on user comprehension and trust.  
Analyses were conducted using **R 4.3**, and results focus on identifying how explanation modality influences perceived understanding, satisfaction, and behavioral intention.

---

## ğŸ§° Environment Setup

Clone the repository and install dependencies using Poetry:

```bash
poetry install
```

Then activate the environment:

```bash
poetry shell
```

## ğŸªª Contact

For questions or collaboration requests, please contact:  
**flore.vromman@gmail.com**

---

## ğŸ“œ License

This project is distributed under an open academic license.  
Please contact the authors for reuse or redistribution inquiries.
